# ğŸ“ˆ Sistema RAG - Asistente de InversiÃ³n en Dividendos

Un sistema completo de **Retrieval-Augmented Generation (RAG)** especializado en inversiÃ³n en dividendos, desarrollado como parte del curso de AI Engineering de KeepCoding.

## ğŸ¯ DescripciÃ³n del Proyecto

Este proyecto implementa un asistente inteligente capaz de responder preguntas especÃ­ficas sobre estrategias de inversiÃ³n en dividendos, anÃ¡lisis financiero y gestiÃ³n de carteras. El sistema utiliza un extenso corpus de conocimiento especializado para proporcionar respuestas precisas y educativas.

## ğŸ“Š CaracterÃ­sticas Principales

### ğŸ§  **Inteligencia Artificial Avanzada**
- **LLM Principal**: GPT-4o-mini para generaciÃ³n de respuestas
- **Embeddings**: OpenAI text-embedding-3-large (3,072 dimensiones)
- **ExtracciÃ³n de Metadatos**: GPT-4o para anÃ¡lisis automÃ¡tico de contenido

### ğŸ“š **Base de Conocimiento Especializada**
- **93 documentos** de contenido financiero procesado
- **Pipeline de calidad**: Audio â†’ TranscripciÃ³n â†’ OptimizaciÃ³n con IA â†’ Textos estructurados
- **Ãreas temÃ¡ticas**: AnÃ¡lisis fundamental, selecciÃ³n de brokers, psicologÃ­a de inversiÃ³n, gestiÃ³n de riesgo, fiscalidad, ratios financieros
- **OrganizaciÃ³n modular**: 16 mÃ³dulos temÃ¡ticos + material complementario

### ğŸ” **Sistema de BÃºsqueda Avanzado**
- **Vector Store**: FAISS para bÃºsqueda semÃ¡ntica eficiente
- **MÃºltiples estrategias de retrieval**: Similarity, MMR, Threshold-based
- **Filtros por metadatos**: Nivel de dificultad, mÃ³dulo, tipo de contenido
- **Chunking inteligente**: RecursiveCharacterTextSplitter optimizado

### âš¡ **Optimizaciones de Rendimiento**
- **Persistencia inteligente**: Chunks y vector store guardados en Google Drive
- **Carga incremental**: Evita reprocesamiento en ejecuciones posteriores
- **Pipeline LCEL**: LangChain Expression Language para mÃ¡xima eficiencia

## ğŸ—ï¸ Arquitectura del Sistema

### ğŸ“Š **Diagrama de Funcionamiento**

El siguiente diagrama muestra el flujo completo del sistema RAG, desde el procesamiento inicial hasta la generaciÃ³n de respuestas:

```mermaid
graph TD
    A["ğŸ™ï¸ Audio Financiero<br/>93 lecciones"] --> B["ğŸ“ TranscripciÃ³n<br/>OpenAI Whisper"]
    B --> C["ğŸ§  OptimizaciÃ³n IA<br/>GPT-4o"]
    C --> D["ğŸ“„ Documentos .txt<br/>Contenido estructurado"]
    
    D --> E["ğŸ“š Document Loading<br/>LangChain TextLoader"]
    E --> F["âœ‚ï¸ Chunking<br/>RecursiveCharacterTextSplitter<br/>1000 chars, 150 overlap"]
    F --> G["ğŸ¤– Metadata Extraction<br/>GPT-4o analiza contenido"]
    
    G --> H["ğŸ“‹ Chunks Enriquecidos<br/>â€¢ main_topic<br/>â€¢ level<br/>â€¢ module<br/>â€¢ content_type"]
    
    H --> I["ğŸ§® Embedding<br/>OpenAI text-embedding-3-large<br/>3,072 dimensiones"]
    I --> J["ğŸ—„ï¸ Vector Store<br/>FAISS Index<br/>BÃºsqueda semÃ¡ntica"]
    
    K["â“ Pregunta Usuario<br/>'Â¿QuÃ© son los dividendos?'"] --> L["ğŸ” Retrieval<br/>BÃºsqueda semÃ¡ntica<br/>Top-K chunks relevantes"]
    
    J --> L
    L --> M["ğŸ“Š Filtros Opcionales<br/>â€¢ Por nivel<br/>â€¢ Por mÃ³dulo<br/>â€¢ Por tipo contenido"]
    
    M --> N["ğŸ“ Contexto Relevante<br/>Chunks seleccionados<br/>+ metadatos"]
    N --> O["ğŸ¤– Generation<br/>GPT-4o-mini<br/>Prompt especializado"]
    
    O --> P["ğŸ’¬ Respuesta Final<br/>â€¢ Respuesta contextualizada<br/>â€¢ Fuentes consultadas<br/>â€¢ Metadatos transparentes"]
    
    Q["ğŸ’¾ Google Drive<br/>Persistencia"] --> J
    H --> Q
    
    style A fill:#e1f5fe
    style P fill:#c8e6c9
    style J fill:#fff3e0
    style O fill:#f3e5f5
    style K fill:#ffebee
```

### ğŸ“‹ **Metadatos Enriquecidos**
Cada chunk incluye:
- `main_topic`: Tema principal extraÃ­do con GPT-4o
- `level`: Nivel de dificultad (bÃ¡sico, intermedio, avanzado)
- `module`: NÃºmero de mÃ³dulo del curso
- `lesson`: NÃºmero de lecciÃ³n
- `content_type`: Tipo de contenido (lecciÃ³n, introducciÃ³n, bonus, etc.)
- `chunk_tokens`: NÃºmero de tokens para optimizaciÃ³n

### ğŸ”„ **Pipeline de Procesamiento**
1. **Document Loading**: Carga de archivos .txt con LangChain
2. **Chunking**: SegmentaciÃ³n con solapamiento para preservar contexto
3. **Metadata Extraction**: AnÃ¡lisis automÃ¡tico con GPT-4o
4. **Embedding**: VectorizaciÃ³n con OpenAI embeddings
5. **Indexing**: CreaciÃ³n de Ã­ndice FAISS para bÃºsqueda rÃ¡pida
6. **Retrieval**: BÃºsqueda semÃ¡ntica con filtros
7. **Generation**: Respuesta contextualizada con GPT-4o-mini

## ğŸ› ï¸ Stack TecnolÃ³gico

- **ğŸ¦œ LangChain**: Framework para aplicaciones RAG
- **ğŸ¤– OpenAI**: GPT-4o-mini, GPT-4o, text-embedding-3-large
- **ğŸ” FAISS**: Base de datos vectorial de Meta AI
- **ğŸ“Š Python**: Procesamiento de datos y anÃ¡lisis
- **â˜ï¸ Google Colab**: Entorno de desarrollo y ejecuciÃ³n
- **ğŸ’¾ Google Drive**: Persistencia de datos procesados

## ğŸš€ Instrucciones de Uso

### 1. **PreparaciÃ³n del Entorno**
```python
# Instalar dependencias
!pip install langchain langchain-openai langchain-community faiss-cpu tiktoken tqdm pandas matplotlib seaborn openai

# Configurar API Key
import os
import getpass
os.environ["OPENAI_API_KEY"] = getpass.getpass("Introduce tu OpenAI API Key: ")
```

### 2. **Carga de Datos**
- Sube el archivo `data.zip` con los documentos procesados
- El sistema detectarÃ¡ automÃ¡ticamente si ya existen chunks procesados en Google Drive

### 3. **Consultas al Sistema**
```python
# Consulta bÃ¡sica
response = ask_dividends_expert("Â¿QuÃ© son los dividendos?")

# Consulta con retriever especÃ­fico
response = ask_dividends_expert(
    "Â¿CuÃ¡les son las ventajas de invertir en dividendos?", 
    retriever_type="similarity"
)

# BÃºsqueda con filtros
filtered_results = search_with_filters(
    "dividendos", 
    level="intermedio", 
    module=2, 
    k=5
)
```

## ğŸ“ˆ Tipos de Consultas Soportadas

- **Conceptos fundamentales**: Â¿QuÃ© son los dividendos? Â¿CÃ³mo funcionan?
- **Estrategias de inversiÃ³n**: SelecciÃ³n de acciones, diversificaciÃ³n, timing
- **AnÃ¡lisis financiero**: Ratios, mÃ©tricas, evaluaciÃ³n de empresas
- **GestiÃ³n de riesgo**: IdentificaciÃ³n y mitigaciÃ³n de riesgos
- **Aspectos fiscales**: TributaciÃ³n de dividendos, optimizaciÃ³n fiscal
- **PsicologÃ­a de inversiÃ³n**: Sesgos cognitivos, disciplina financiera

## ğŸ¯ Ventajas del Sistema

### âœ… **PrecisiÃ³n y Relevancia**
- Respuestas basadas Ãºnicamente en el corpus especializado
- Sistema anti-alucinaciÃ³n que indica cuando no tiene informaciÃ³n
- Contexto financiero especÃ­fico en todas las respuestas

### âœ… **Transparencia**
- Fuentes consultadas visibles en cada respuesta
- Metadatos completos de cada documento utilizado
- Trazabilidad completa del proceso de generaciÃ³n

### âœ… **Flexibilidad**
- MÃºltiples estrategias de retrieval segÃºn el caso de uso
- Filtros avanzados por nivel, mÃ³dulo y tipo de contenido
- ConfiguraciÃ³n adaptable a diferentes necesidades

### âœ… **Eficiencia**
- Persistencia inteligente evita reprocesamiento
- Pipeline optimizado con LCEL
- BÃºsqueda vectorial ultra-rÃ¡pida con FAISS

## ğŸ“Š EstadÃ­sticas del Dataset

- **ğŸ“š Documentos**: 93 archivos de texto procesados
- **ğŸ§© Chunks**: ~500-800 fragmentos (segÃºn configuraciÃ³n)
- **ğŸ“ TamaÃ±o promedio**: ~1,000 caracteres por chunk
- **ğŸ”¤ Tokens promedio**: ~250 tokens por chunk
- **ğŸ“ Dimensiones embedding**: 3,072 (text-embedding-3-large)

## ğŸ”§ ConfiguraciÃ³n Avanzada

### **ParÃ¡metros de Chunking**
```python
chunk_size=1000,           # TamaÃ±o mÃ¡ximo del chunk
chunk_overlap=150,         # Solapamiento entre chunks
separators=["\\n\\n", "\\n", ". "]  # Separadores preferenciales
```

### **ConfiguraciÃ³n de Retrievers**
```python
# BÃ¡sico: Top 5 mÃ¡s similares
basic_retriever = vectorstore.as_retriever(search_kwargs={"k": 5})

# Con threshold: Solo chunks muy relevantes
similarity_retriever = vectorstore.as_retriever(
    search_type="similarity_score_threshold",
    search_kwargs={"k": 10, "score_threshold": 0.5}
)

# MMR: Balance entre relevancia y diversidad
mmr_retriever = vectorstore.as_retriever(
    search_type="mmr",
    search_kwargs={"k": 5, "fetch_k": 20, "lambda_mult": 0.7}
)
```

## ğŸ“ Contexto AcadÃ©mico

Este proyecto fue desarrollado como parte del **Curso de AI Engineering de KeepCoding**, demostrando:

- ImplementaciÃ³n completa de un sistema RAG
- Procesamiento y optimizaciÃ³n de datasets reales
- IntegraciÃ³n de mÃºltiples tecnologÃ­as de IA
- Buenas prÃ¡cticas en ingenierÃ­a de prompts
- OptimizaciÃ³n de rendimiento y costos
- EvaluaciÃ³n y testing de sistemas de IA

